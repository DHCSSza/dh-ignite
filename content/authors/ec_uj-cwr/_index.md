---
# Display name
title: "Eleanor Cornelius"

# Is this the primary user of the site?
superuser: false

# Role/position/tagline
role: "Using automated text analyzers in plain language research"

user_groups: ["Speakers Aug '23"]

# Organizations/Affiliations to show in About widget
organizations:
 - name: UJ
 - url: 

# Short bio (displayed in user profile at end of posts)
bio: 

# Interests to show in About widget
interests: 

# Education to show in About widget
education:


# Social/Academic Networking
# For available icons, see: https://sourcethemes.com/academic/docs/page-builder/#icons
#   For an email link, use "fas" icon pack, "envelope" icon, and a link in the
#   form "mailto:your-email@example.com" or "/#contact" for contact widget.


# Link to a PDF of your resume/CV.
# To use: copy your resume to `static/media/resume.pdf`, enable `ai` icons in `params.toml`, 
# and uncomment the lines below.
# - icon: cv
#   icon_pack: ai
#   link: media/resume.pdf

# Enter email to display Gravatar (if Gravatar enabled in Config)
email: ""

# Highlight the author in author lists? (true/false)
highlight_name: false
---

## Date

24 August 2023

## Time

14:00

## Session

Case-studies: Showcasing examples of humanities/social sciences research projects with computational/digital element

## Abstract

Researchers working in the field of plain language require automated tools to speed up the rate of and enhance accuracy levels during data analysis. Lexical density is the proportion of lexical items from different word classes (e.g. nouns, verbs, etc.). Texts with lower lexical density are easier to understand than those with higher lexical density (Gregori-Signes &amp; Clavel-Arroitia, 2015), in  particular reference to the use of nouns and nominalisations in written texts, such as news reports and press releases. The use of free automated text analyzers, such as Analyze My Writing (https://www.analyzemywriting.com/) and SEO Scout (https://seoscout.com/), are useful text analyzers to identify sources of processing difficulty and cognitive load in texts. Apart from calculating lexical density, these tools also provide basic text statistics (such as word count, and word and sentence length), lexical diversity, readability scores, sentiment, content analysis, passive constructions, and more.

## Bio

Eleanor Cornelius is a professor in applied linguistics at the University of Johannesburg and an NRF rated researcher. She is best known for her pioneering research in the field of plain language and her research into legal translation and the peculiarities of legal language. She investigates real-world language problems in mainly the corporate and legal domains, focusing on the comprehension difficulties that arise as a result of opaque language, and she attempts to suggest practical and implementable solutions to these problems in different domains of society. In her research, she often uses automated text analyzers.

Eleanor is the immediate past chairperson of the South African Translators' Institute (SATI) and a SATI accredited simultaneous interpreter. She is a vice president of the International Federation of Translators (FIT) and vice chair of FIT Africa. She is the vice chair of the FIT Taskforce on Technology. Additionally, she serves on the Board of the newly established South African Language Practitionersâ€™ Council (SALPC). As an invited member, she forms part of the International Working Group for Community Translation, and she has been a member of the programming committee of Asling's Translating and the Computer for a number of years. Locally, she is a member of the scientific advisory council (SAC) of SADiLAR, a member of the advisory panel of the language committee of the South African Academy of Science and Art (SAAWK) and a member of SABS/TC 0037/WG 11 "Plain language".


